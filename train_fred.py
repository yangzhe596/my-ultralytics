#!/usr/bin/env python
# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

# -*- coding: utf-8 -*-
"""
FRED æ•°æ®é›†è®­ç»ƒè„šæœ¬ - YAMLé…ç½®ç‰ˆæœ¬
ä»YAMLé…ç½®æ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰è®­ç»ƒå‚æ•°.
"""

import argparse
import logging
import sys
from pathlib import Path

import yaml

from ultralytics import YOLO

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
LOGGER = logging.getLogger(__name__)


def load_config(config_path):
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶."""
    try:
        with open(config_path, encoding="utf-8") as f:
            config = yaml.safe_load(f)
        LOGGER.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        return config
    except Exception as e:
        LOGGER.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)


def get_dataset_config(config):
    """è·å–æ•°æ®é›†é…ç½®."""
    dataset_config = config["dataset"]
    use_simple = dataset_config["use_simple"]

    if use_simple:
        return dataset_config["simple"]
    else:
        return dataset_config["full"]


def get_training_args(config, dataset_cfg, config_path, project_root):
    """æ„å»ºè®­ç»ƒå‚æ•°."""
    training_cfg = config["training"]
    model_cfg = config["model"]

    # åŸºç¡€è®­ç»ƒå‚æ•°
    train_args = {
        "data": str(config_path),
        "epochs": training_cfg["epochs"],
        "imgsz": training_cfg["imgsz"],
        "batch": training_cfg["batch_size"],
        "device": training_cfg["device"],
        "project": str(project_root / training_cfg["project"]),
        "name": f"{dataset_cfg['name_prefix']}_{model_cfg['size']}",
        "exist_ok": training_cfg["exist_ok"],
        "pretrained": training_cfg["pretrained"],
    }

    # å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨å‚æ•°
    train_args.update(
        {
            "lr0": training_cfg["lr0"],
            "lrf": training_cfg.get("lrf", training_cfg["lr0"] * 0.01),
            "optimizer": training_cfg["optimizer"],
            "momentum": training_cfg["momentum"],
            "weight_decay": training_cfg["weight_decay"],
        }
    )

    # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
    train_args.update(
        {
            "warmup_epochs": training_cfg["warmup_epochs"],
            "warmup_momentum": training_cfg["warmup_momentum"],
            "warmup_bias_lr": training_cfg["warmup_bias_lr"],
        }
    )

    # æ•°æ®å¢å¼ºå‚æ•°
    train_args.update(
        {
            "hsv_h": training_cfg["hsv_h"],
            "hsv_s": training_cfg["hsv_s"],
            "hsv_v": training_cfg["hsv_v"],
            "degrees": training_cfg["degrees"],
            "translate": training_cfg["translate"],
            "scale": training_cfg["scale"],
            "shear": training_cfg["shear"],
            "perspective": training_cfg["perspective"],
            "flipud": training_cfg["flipud"],
            "fliplr": training_cfg["fliplr"],
            "mosaic": training_cfg["mosaic"],
            "mixup": training_cfg["mixup"],
        }
    )

    # è®­ç»ƒæ§åˆ¶å‚æ•°
    train_args.update(
        {
            "patience": training_cfg["patience"],
            "save_period": training_cfg["save_period"],
            "workers": training_cfg["workers"],
            "close_mosaic": training_cfg["close_mosaic"],
        }
    )

    # è¾“å‡ºå‚æ•°
    output_cfg = config["output"]
    train_args.update(
        {
            "conf": output_cfg["conf"],
            "iou": output_cfg["iou"],
            "max_det": output_cfg["max_det"],
        }
    )

    # å¯è§†åŒ–å‚æ•°
    viz_cfg = config.get("visualization", {})
    train_args.update(
        {
            "plots": viz_cfg.get("plots", False),
            "visualize": viz_cfg.get("visualize", False),
        }
    )

    # é«˜çº§å‚æ•°
    adv_cfg = config.get("advanced", {})
    train_args.update(
        {
            "rect": adv_cfg.get("rect", False),
            "cos_lr": adv_cfg.get("cos_lr", False),
            "nbs": adv_cfg.get("nbs", 64),
            "amp": False,  # ç¦ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ä»¥é˜²æ­¢NaN
        }
    )

    # å†»ç»“å‚æ•°
    train_args["freeze"] = dataset_cfg.get("freeze", 0)

    return train_args, model_cfg


def train_model(config_path, config):
    """è®­ç»ƒæ¨¡å‹."""
    # è·å–æ•°æ®é›†é…ç½®
    dataset_cfg = get_dataset_config(config)
    LOGGER.info(f"ä½¿ç”¨æ•°æ®é›†é…ç½®: {dataset_cfg['name_prefix']}")

    # è·å–æ¨¡å‹é…ç½®
    model_cfg = config["model"]
    model_name = f"yolov8{model_cfg['size']}.pt"
    LOGGER.info(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_name}")

    # åŠ è½½æ¨¡å‹
    try:
        model = YOLO(model_name)
    except Exception as e:
        LOGGER.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return False

    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(__file__).parent

    # æ„å»ºè®­ç»ƒå‚æ•°
    train_args, model_cfg = get_training_args(config, dataset_cfg, config_path, project_root)

    # è·å–å†»ç»“é…ç½®
    freeze_layers = dataset_cfg.get("freeze", 0)
    freeze_epochs = dataset_cfg.get("freeze_epochs", 0)
    test_after_train = config["training"]["test_after_train"]

    # å¦‚æœéœ€è¦å†»ç»“è®­ç»ƒï¼Œè¿›è¡Œä¸¤é˜¶æ®µè®­ç»ƒ
    if freeze_layers > 0 and freeze_epochs > 0:
        LOGGER.info(
            f"ä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼šå†»ç»“ {freeze_layers} å±‚è®­ç»ƒ {freeze_epochs} è½®ï¼Œç„¶åè§£å†»å…¨é‡è®­ç»ƒ {config['training']['epochs'] - freeze_epochs} è½®"
        )

        # ç¬¬ä¸€é˜¶æ®µï¼šå†»ç»“è®­ç»ƒ
        LOGGER.info("=== ç¬¬ä¸€é˜¶æ®µï¼šå†»ç»“è®­ç»ƒ ===")
        freeze_args = train_args.copy()
        freeze_args.update(
            {
                "epochs": freeze_epochs,
                "name": f"{dataset_cfg['name_prefix']}_{model_cfg['size']}_freeze",
                "freeze": freeze_layers,
                "lr0": model_cfg["stage1_lr"],
            }
        )

        try:
            results = model.train(**freeze_args)
            LOGGER.info("ç¬¬ä¸€é˜¶æ®µè®­ç»ƒå®Œæˆ!")

            # ä½¿ç”¨ç¬¬ä¸€é˜¶æ®µè®­ç»ƒçš„ç»“æœç»§ç»­è®­ç»ƒ
            model = YOLO(str(results.save_dir / "weights/best.pt"))

        except Exception as e:
            LOGGER.error(f"ç¬¬ä¸€é˜¶æ®µè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False

        # ç¬¬äºŒé˜¶æ®µï¼šè§£å†»è®­ç»ƒ
        LOGGER.info("=== ç¬¬äºŒé˜¶æ®µï¼šè§£å†»å…¨é‡è®­ç»ƒ ===")
        unfreeze_args = train_args.copy()
        unfreeze_args.update(
            {
                "name": f"{dataset_cfg['name_prefix']}_{model_cfg['size']}_full",
                "freeze": 0,  # è§£å†»æ‰€æœ‰å±‚
                "lr0": model_cfg["stage2_lr"],  # é™ä½å­¦ä¹ ç‡
                "pretrained": False,  # ä½¿ç”¨ç¬¬ä¸€é˜¶æ®µè®­ç»ƒçš„æ¨¡å‹
                # ç§»é™¤ 'resume': Trueï¼Œæ”¹ä¸ºä½¿ç”¨ç¬¬ä¸€é˜¶æ®µè®­ç»ƒçš„æ¨¡å‹ä½œä¸ºèµ·ç‚¹
            }
        )

        train_args = unfreeze_args
    else:
        # å•é˜¶æ®µè®­ç»ƒ
        train_args["freeze"] = freeze_layers

    # å¼€å§‹è®­ç»ƒ
    LOGGER.info("å¼€å§‹è®­ç»ƒ...")
    try:
        results = model.train(**train_args)
        LOGGER.info("è®­ç»ƒå®Œæˆ!")

        # ä¿å­˜æœ€ä½³æ¨¡å‹è·¯å¾„
        best_model_path = results.save_dir / "weights/best.pt"
        LOGGER.info(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")

        # è¿è¡ŒéªŒè¯
        LOGGER.info("è¿è¡ŒéªŒè¯...")
        metrics = model.val(data=str(config_path))
        LOGGER.info(f"éªŒè¯ç»“æœ: mAP50={metrics.box.map50:.4f}, mAP50-95={metrics.box.map:.4f}")

        # è®­ç»ƒå®Œæˆååœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        if test_after_train:
            LOGGER.info("\n=== åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹ ===")
            try:
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
                test_results = model.val(
                    data=str(config_path),
                    split="test",  # æŒ‡å®šä½¿ç”¨æµ‹è¯•é›†
                    imgsz=config["training"]["imgsz"],
                    device=config["training"]["device"],
                    batch=config["training"]["batch_size"],
                    project=str(project_root / "runs/test"),
                    name=f"{dataset_cfg['name_prefix']}_{model_cfg['size']}_test",
                    exist_ok=True,
                )

                # æ‰“å°æµ‹è¯•ç»“æœ
                LOGGER.info("\næµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
                LOGGER.info(f"  mAP50: {test_results.box.map50:.4f}")
                LOGGER.info(f"  mAP50-95: {test_results.box.map:.4f}")
                LOGGER.info(f"  ç²¾ç¡®ç‡: {test_results.box.mp:.4f}")
                LOGGER.info(f"  å¬å›ç‡: {test_results.box.mr:.4f}")

                # ä¿å­˜æµ‹è¯•ç»“æœ
                test_results_path = results.save_dir / "test_results.txt"
                with open(test_results_path, "w") as f:
                    f.write(f"mAP50: {test_results.box.map50:.4f}\n")
                    f.write(f"mAP50-95: {test_results.box.map:.4f}\n")
                    f.write(f"Precision: {test_results.box.mp:.4f}\n")
                    f.write(f"Recall: {test_results.box.mr:.4f}\n")

                LOGGER.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_results_path}")

            except Exception as e:
                LOGGER.warning(f"æµ‹è¯•é›†è¯„ä¼°å¤±è´¥: {e}")
                LOGGER.info("è¿™å¯èƒ½æ˜¯å› ä¸ºæ•°æ®é›†ä¸­æ²¡æœ‰æµ‹è¯•é›†ï¼Œæˆ–è€…æµ‹è¯•é›†ä¸ºç©º")

        return True

    except Exception as e:
        LOGGER.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°."""
    parser = argparse.ArgumentParser(description="FRED æ•°æ®é›†è®­ç»ƒè„šæœ¬ - YAMLé…ç½®ç‰ˆæœ¬")
    parser.add_argument("--config", type=str, default="datasets/fred_train_config.yaml", help="è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dataset-config", type=str, help="æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰")

    args = parser.parse_args()

    # åŠ è½½é…ç½®æ–‡ä»¶
    config = load_config(args.config)

    # å¦‚æœæŒ‡å®šäº†æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
    if args.dataset_config:
        config["dataset"]["full"]["config_file"] = args.dataset_config
        config["dataset"]["simple"]["config_file"] = args.dataset_config

    # è·å–æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
    dataset_cfg = get_dataset_config(config)
    config_path = dataset_cfg["config_file"]

    # æ£€æŸ¥æ•°æ®é›†é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(config_path).exists():
        LOGGER.error(f"æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return 1

    # è®­ç»ƒæ¨¡å‹
    success = train_model(config_path, config)

    if success:
        LOGGER.info("\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!")
        return 0
    else:
        LOGGER.error("\nâŒ è®­ç»ƒå¤±è´¥!")
        return 1


if __name__ == "__main__":
    sys.exit(main())
